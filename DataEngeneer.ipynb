{"cells":[{"cell_type":"code","source":["dbutils.fs.unmount(\"/mnt/pyspark\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b7e2111-4fb3-48de-85dd-153d9d6ff517"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/mnt/pyspark has been unmounted.\nOut[8]: True</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/mnt/pyspark has been unmounted.\nOut[8]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import urllib\nACCESS_KEY = \"xxxxxxxxxxxxxxxxxx\"\nSECRET_KEY = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n\nENCODED_SECRET_KEY = urllib.parse.quote(SECRET_KEY, \"\")\nAWS_BUCKET_NAME = \"dev-databricks-test\"\nMOUNT_NAME = \"pyspark\"\ndbutils.fs.mount(\"s3n://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9748da9-788b-4ca8-82aa-4fd6ec24ea95"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[9]: True</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["SECRET_KEY.replace(\"/\", \"%2F\")\ndisplay(dbutils.fs.ls(\"/mnt/pyspark/\"))\n#display(dbutils.fs.ls(\"/mnt/foldername/\"))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66e43445-d11c-4dec-98e4-99943bd8f250"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1609828227945815&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> SECRET_KEY<span class=\"ansi-blue-fg\">.</span>replace<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;/&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;%2F&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>display<span class=\"ansi-blue-fg\">(</span>dbutils<span class=\"ansi-blue-fg\">.</span>fs<span class=\"ansi-blue-fg\">.</span>ls<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;/mnt/pyspark/&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> <span class=\"ansi-red-fg\">#display(dbutils.fs.ls(&#34;/mnt/foldername/&#34;))</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1602954357639-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    312</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    313</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 314</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    315</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n<span class=\"ansi-green-intense-fg ansi-bold\">    316</span> \n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling z:com.databricks.backend.daemon.dbutils.FSUtils.ls.\n: java.rmi.RemoteException: com.databricks.s3.S3Exception: org.jets3t.service.S3ServiceException: S3 GET failed for &#39;/&#39; XML Error Message: &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;Error&gt;&lt;Code&gt;InvalidRequest&lt;/Code&gt;&lt;Message&gt;The authorization mechanism you have provided is not supported. Please use AWS4-HMAC-SHA256.&lt;/Message&gt;&lt;RequestId&gt;96A6581B607B3B87&lt;/RequestId&gt;&lt;HostId&gt;c3Y0AbInqSWt65maKYtqMDgs+W7PwATcev4fHYaJIlmjvHNZNs7MVGIv0sKNRxuGyqPOAPD0rbk=&lt;/HostId&gt;&lt;/Error&gt;; nested exception is: \n\tcom.databricks.s3.S3Exception: org.jets3t.service.S3ServiceException: S3 GET failed for &#39;/&#39; XML Error Message: &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;Error&gt;&lt;Code&gt;InvalidRequest&lt;/Code&gt;&lt;Message&gt;The authorization mechanism you have provided is not supported. Please use AWS4-HMAC-SHA256.&lt;/Message&gt;&lt;RequestId&gt;96A6581B607B3B87&lt;/RequestId&gt;&lt;HostId&gt;c3Y0AbInqSWt65maKYtqMDgs+W7PwATcev4fHYaJIlmjvHNZNs7MVGIv0sKNRxuGyqPOAPD0rbk=&lt;/HostId&gt;&lt;/Error&gt;\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:123)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:63)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.listStatus(DatabricksFileSystemV1.scala:177)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:150)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.$anonfun$ls$1(DBUtilsCore.scala:86)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.withFsSafetyCheck(DBUtilsCore.scala:81)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.ls(DBUtilsCore.scala:85)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.ls(DBUtilsCore.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: com.databricks.s3.S3Exception: org.jets3t.service.S3ServiceException: S3 GET failed for &#39;/&#39; XML Error Message: &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;Error&gt;&lt;Code&gt;InvalidRequest&lt;/Code&gt;&lt;Message&gt;The authorization mechanism you have provided is not supported. Please use AWS4-HMAC-SHA256.&lt;/Message&gt;&lt;RequestId&gt;96A6581B607B3B87&lt;/RequestId&gt;&lt;HostId&gt;c3Y0AbInqSWt65maKYtqMDgs+W7PwATcev4fHYaJIlmjvHNZNs7MVGIv0sKNRxuGyqPOAPD0rbk=&lt;/HostId&gt;&lt;/Error&gt;\n\tat com.databricks.s3.Jets3tNativeFileSystemStore.handleServiceException(Jets3tNativeFileSystemStore.java:280)\n\tat com.databricks.s3.Jets3tNativeFileSystemStore.list(Jets3tNativeFileSystemStore.java:211)\n\tat com.databricks.s3.Jets3tNativeFileSystemStore.list(Jets3tNativeFileSystemStore.java:182)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n\tat com.sun.proxy.$Proxy23.list(null)\n\tat com.databricks.s3.StableNativeS3FileSystem.listStatus(StableNativeS3FileSystem.java:374)\n\tat com.databricks.backend.daemon.data.server.backend.HadoopFSBackend.listStatus(HadoopFSBackend.scala:99)\n\tat com.databricks.backend.daemon.data.server.backend.FileSystemBackend.listStatus(FileSystemBackend.scala:36)\n\tat com.databricks.backend.daemon.data.server.backend.FileSystemBackend.listStatus$(FileSystemBackend.scala:32)\n\tat com.databricks.backend.daemon.data.server.backend.HadoopFSBackend.listStatus(HadoopFSBackend.scala:19)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.$anonfun$listStatus$2(RootFileSystemBackend.scala:90)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$4(UsageLogging.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.withAttributionContext(RootFileSystemBackend.scala:28)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.withAttributionTags(RootFileSystemBackend.scala:28)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:338)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.recordOperation(RootFileSystemBackend.scala:28)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.listStatus(RootFileSystemBackend.scala:86)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.$anonfun$receive$6(FileSystemRequestHandler.scala:59)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$4(UsageLogging.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.withAttributionContext(FileSystemRequestHandler.scala:23)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.withAttributionTags(FileSystemRequestHandler.scala:23)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:338)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.recordOperation(FileSystemRequestHandler.scala:23)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.receive(FileSystemRequestHandler.scala:59)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:97)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:96)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:96)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:344)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:312)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:53)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:80)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:80)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:49)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$4(UsageLogging.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:16)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:16)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:338)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:16)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:48)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:637)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:637)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:560)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$4(JettyServer.scala:327)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:156)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:156)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:315)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:223)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\t... 1 more\nCaused by: java.lang.Throwable: S3 GET failed for &#39;/&#39;\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.performRequest(RestS3Service.java:418)\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.performRestGet(RestS3Service.java:753)\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.listObjectsInternal(RestS3Service.java:1118)\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.listObjectsChunkedImpl(RestS3Service.java:1088)\n\tat org.jets3t.service.S3Service.listObjectsChunked(S3Service.java:1488)\n\tat com.databricks.s3.Jets3tNativeFileSystemStore.list(Jets3tNativeFileSystemStore.java:199)\n\t... 100 more\n</div>","errorSummary":"java.rmi.RemoteException: com.databricks.s3.S3Exception: org.jets3t.service.S3ServiceException: S3 GET failed for &#39;/&#39; XML Error Message: &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;Error&gt;&lt;Code&gt;InvalidRequest&lt;/Code&gt;&lt;Message&gt;The authorization mechanism you have provided is not supported. Please use AWS4-HMAC-SHA256.&lt;/Message&gt;&lt;RequestId&gt;96A6581B607B3B87&lt;/RequestId&gt;&lt;HostId&gt;c3Y0AbInqSWt65maKYtqMDgs+W7PwATcev4fHYaJIlmjvHNZNs7MVGIv0sKNRxuGyqPOAPD0rbk=&lt;/HostId&gt;&lt;/Error&gt;; nested exception is: ","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1609828227945815&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> SECRET_KEY<span class=\"ansi-blue-fg\">.</span>replace<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;/&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;%2F&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>display<span class=\"ansi-blue-fg\">(</span>dbutils<span class=\"ansi-blue-fg\">.</span>fs<span class=\"ansi-blue-fg\">.</span>ls<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;/mnt/pyspark/&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> <span class=\"ansi-red-fg\">#display(dbutils.fs.ls(&#34;/mnt/foldername/&#34;))</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1602954357639-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    312</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    313</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 314</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    315</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n<span class=\"ansi-green-intense-fg ansi-bold\">    316</span> \n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling z:com.databricks.backend.daemon.dbutils.FSUtils.ls.\n: java.rmi.RemoteException: com.databricks.s3.S3Exception: org.jets3t.service.S3ServiceException: S3 GET failed for &#39;/&#39; XML Error Message: &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;Error&gt;&lt;Code&gt;InvalidRequest&lt;/Code&gt;&lt;Message&gt;The authorization mechanism you have provided is not supported. Please use AWS4-HMAC-SHA256.&lt;/Message&gt;&lt;RequestId&gt;96A6581B607B3B87&lt;/RequestId&gt;&lt;HostId&gt;c3Y0AbInqSWt65maKYtqMDgs+W7PwATcev4fHYaJIlmjvHNZNs7MVGIv0sKNRxuGyqPOAPD0rbk=&lt;/HostId&gt;&lt;/Error&gt;; nested exception is: \n\tcom.databricks.s3.S3Exception: org.jets3t.service.S3ServiceException: S3 GET failed for &#39;/&#39; XML Error Message: &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;Error&gt;&lt;Code&gt;InvalidRequest&lt;/Code&gt;&lt;Message&gt;The authorization mechanism you have provided is not supported. Please use AWS4-HMAC-SHA256.&lt;/Message&gt;&lt;RequestId&gt;96A6581B607B3B87&lt;/RequestId&gt;&lt;HostId&gt;c3Y0AbInqSWt65maKYtqMDgs+W7PwATcev4fHYaJIlmjvHNZNs7MVGIv0sKNRxuGyqPOAPD0rbk=&lt;/HostId&gt;&lt;/Error&gt;\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:123)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:63)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.listStatus(DatabricksFileSystemV1.scala:177)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:150)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.$anonfun$ls$1(DBUtilsCore.scala:86)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.withFsSafetyCheck(DBUtilsCore.scala:81)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.ls(DBUtilsCore.scala:85)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.ls(DBUtilsCore.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: com.databricks.s3.S3Exception: org.jets3t.service.S3ServiceException: S3 GET failed for &#39;/&#39; XML Error Message: &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;Error&gt;&lt;Code&gt;InvalidRequest&lt;/Code&gt;&lt;Message&gt;The authorization mechanism you have provided is not supported. Please use AWS4-HMAC-SHA256.&lt;/Message&gt;&lt;RequestId&gt;96A6581B607B3B87&lt;/RequestId&gt;&lt;HostId&gt;c3Y0AbInqSWt65maKYtqMDgs+W7PwATcev4fHYaJIlmjvHNZNs7MVGIv0sKNRxuGyqPOAPD0rbk=&lt;/HostId&gt;&lt;/Error&gt;\n\tat com.databricks.s3.Jets3tNativeFileSystemStore.handleServiceException(Jets3tNativeFileSystemStore.java:280)\n\tat com.databricks.s3.Jets3tNativeFileSystemStore.list(Jets3tNativeFileSystemStore.java:211)\n\tat com.databricks.s3.Jets3tNativeFileSystemStore.list(Jets3tNativeFileSystemStore.java:182)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n\tat com.sun.proxy.$Proxy23.list(null)\n\tat com.databricks.s3.StableNativeS3FileSystem.listStatus(StableNativeS3FileSystem.java:374)\n\tat com.databricks.backend.daemon.data.server.backend.HadoopFSBackend.listStatus(HadoopFSBackend.scala:99)\n\tat com.databricks.backend.daemon.data.server.backend.FileSystemBackend.listStatus(FileSystemBackend.scala:36)\n\tat com.databricks.backend.daemon.data.server.backend.FileSystemBackend.listStatus$(FileSystemBackend.scala:32)\n\tat com.databricks.backend.daemon.data.server.backend.HadoopFSBackend.listStatus(HadoopFSBackend.scala:19)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.$anonfun$listStatus$2(RootFileSystemBackend.scala:90)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$4(UsageLogging.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.withAttributionContext(RootFileSystemBackend.scala:28)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.withAttributionTags(RootFileSystemBackend.scala:28)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:338)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.recordOperation(RootFileSystemBackend.scala:28)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.listStatus(RootFileSystemBackend.scala:86)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.$anonfun$receive$6(FileSystemRequestHandler.scala:59)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$4(UsageLogging.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.withAttributionContext(FileSystemRequestHandler.scala:23)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.withAttributionTags(FileSystemRequestHandler.scala:23)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:338)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.recordOperation(FileSystemRequestHandler.scala:23)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.receive(FileSystemRequestHandler.scala:59)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:97)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:96)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:96)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:344)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:312)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:53)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:80)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:80)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:49)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$4(UsageLogging.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:16)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:16)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:338)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:16)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:48)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:637)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:637)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:560)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$4(JettyServer.scala:327)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:156)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:156)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:315)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:223)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\t... 1 more\nCaused by: java.lang.Throwable: S3 GET failed for &#39;/&#39;\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.performRequest(RestS3Service.java:418)\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.performRestGet(RestS3Service.java:753)\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.listObjectsInternal(RestS3Service.java:1118)\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.listObjectsChunkedImpl(RestS3Service.java:1088)\n\tat org.jets3t.service.S3Service.listObjectsChunked(S3Service.java:1488)\n\tat com.databricks.s3.Jets3tNativeFileSystemStore.list(Jets3tNativeFileSystemStore.java:199)\n\t... 100 more\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["file_location = \"dbfs:/mnt/davs3/listing.csv\"\nfile_type = 'csv'\n\n# csv options\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# the applied options are for csv files. for other file types these will be ignored.\n\ndf_listing = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\ndisplay(df_listing)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ace2603-13b8-46b1-9b47-625bd66a9f32"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1609828227945816&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span>   <span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;header&#34;</span><span class=\"ansi-blue-fg\">,</span> first_row_is_header<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     14</span>   <span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;sep&#34;</span><span class=\"ansi-blue-fg\">,</span> delimiter<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">---&gt; 15</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>file_location<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     16</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     17</span> display<span class=\"ansi-blue-fg\">(</span>df_listing<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    176</span>         self<span class=\"ansi-blue-fg\">.</span>options<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>options<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    177</span>         <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">,</span> basestring<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 178</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    179</span>         <span class=\"ansi-green-fg\">elif</span> path <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    180</span>             <span class=\"ansi-green-fg\">if</span> type<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">!=</span> list<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Path does not exist: dbfs:/mnt/davs3/listing.csv;</div>","errorSummary":"<span class=\"ansi-red-fg\">AnalysisException</span>: Path does not exist: dbfs:/mnt/davs3/listing.csv;","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1609828227945816&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span>   <span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;header&#34;</span><span class=\"ansi-blue-fg\">,</span> first_row_is_header<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     14</span>   <span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;sep&#34;</span><span class=\"ansi-blue-fg\">,</span> delimiter<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">---&gt; 15</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>file_location<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     16</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     17</span> display<span class=\"ansi-blue-fg\">(</span>df_listing<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    176</span>         self<span class=\"ansi-blue-fg\">.</span>options<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>options<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    177</span>         <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">,</span> basestring<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 178</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    179</span>         <span class=\"ansi-green-fg\">elif</span> path <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    180</span>             <span class=\"ansi-green-fg\">if</span> type<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">!=</span> list<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Path does not exist: dbfs:/mnt/davs3/listing.csv;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["file_location"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce93bd44-06c4-4d73-b188-7f76aa973c91"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[4]: &#39;dbfs:/mnt/davs3/listing.csv&#39;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: &#39;dbfs:/mnt/davs3/listing.csv&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"503d4d1b-9d8a-4699-816b-1cc007107409"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DataEngeneer","dashboards":[],"language":"python","widgets":{},"notebookOrigID":1609828227945813}},"nbformat":4,"nbformat_minor":0}
